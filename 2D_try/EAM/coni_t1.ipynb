{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matscipy\n",
    "from matscipy import calculators\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from copy import copy\n",
    "from itertools import combinations\n",
    "import time\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from scipy import constants\n",
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def supercell_gen(cell_num1, cell_num2):\n",
    "    atom_pos1 = cell_num1*2 + 1\n",
    "    atom_pos2 = cell_num2*2 + 1\n",
    "    zero_cell = np.zeros(((atom_pos1, atom_pos2)))\n",
    "    for i in range(atom_pos1):\n",
    "        for j in range(atom_pos2):\n",
    "            if i%2 == 1:\n",
    "                zero_cell[i][j] = abs(j%2)\n",
    "            elif i%2 == 0:\n",
    "                zero_cell[i][j] = 1 - abs(j%2)\n",
    "    return zero_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Read NC's potential for CrCoNi\n",
    "eam_pth = '/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/NiCoCr.lammps_t1.eam'\n",
    "_, param, f_s, rhof_s, phi_r = calculators.eam.io.read_eam(eam_pth, kind='eam/alloy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters based on Zhou et al's work\n",
    "\n",
    "https://journals.aps.org/prb/abstract/10.1103/PhysRevB.69.144113\n",
    "\n",
    "### Main:\n",
    "$$E = 1/2\\sum_{i \\neq j}\\phi_{ij}(r_{ij}) + \\sum_{i}F_i(\\rho_i) \\tag{1-1}$$\n",
    "\n",
    "$$f(r) = \\frac{f_e e^{-\\beta(r/r_e-1)}}{1+(r/r_e-\\lambda)^{20}} \\tag{1-2}$$\n",
    "\n",
    "*variable: f_e, beta, lamda*\n",
    "\n",
    "#### Potential\n",
    "\n",
    "$$\\phi(r) = \\frac{Ae^{-\\alpha(r/r_e-1)}}{1+(r/r_e-\\kappa)^{20}}-\\frac{Be^{-\\beta(r/r_e-1)}}{1+(r/r_e-\\lambda)^{20}} \\tag{2-1}$$\n",
    "\n",
    "*variable: A, B, alpha, beta, kappa, lamda, r_e*\n",
    "\n",
    "$$\\phi^{ab}(r) = 1/2[\\frac{f^b(r)}{f^a(r)}\\phi^{aa}(r)+\\frac{f^a(r)}{f^b(r)}\\phi^{bb}(r)] \\tag{2-2}$$\n",
    "\n",
    "#### Density of electron\n",
    "\n",
    "$$\\rho_i = \\sum_{j \\neq i}f_j(r_{ij}) \\tag{3-1}$$\n",
    "\n",
    "$$F(\\rho) = \n",
    "\\begin{cases}\n",
    "\\sum_{i=0}^{3}F_{ni}(\\rho/\\rho_n-1)^i,\\ \\rho < \\rho_n,\\ \\rho_n = 0.85\\rho_e \\\\\n",
    "\\sum_{i=0}^{3}F_{i}(\\rho/\\rho_e-1)^i,\\ \\rho_n \\leq \\rho < \\rho_0,\\ \\rho_0 = 1.15\\rho_e\\\\\n",
    "F_e[1-\\mathrm{ln}(\\rho/\\rho_s)^{\\eta}](\\rho/\\rho_s)^{\\eta},\\ \\rho_0 \\leq \\rho\n",
    "\\end{cases} \\tag{3-2}$$\n",
    "\n",
    "*variable: rho_e, rho_s, eta, f_n0~f_n3, f_0~f_3*\n",
    "\n",
    "| | r_e | f_e | rho_e | rho_s | alpha | beta | A | B | kappa | lamda |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| INDEX | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |\n",
    "\n",
    "<br />\n",
    "\n",
    "| | f_no | f_n1 | f_n2 | f_n3 | f_0 | f_1 | f_2 | f_3 | eta | f_e | rho_n | rho_0 |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| INDEX | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, atom_list, param_list):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        atom_list: N*dimension\n",
    "        param_list: N*number of params per each atom\n",
    "        per each row:\n",
    "        r_e, f_e, rho_e, rho_s, alpha, beta, A, B, kappa, lamda,\n",
    "        f_n0, f_n1, f_n2, f_n3, f_0, f_1, f_2, f_3, eta, f_e\n",
    "        '''\n",
    "        #* row1: x-coord, row2: y-coord\n",
    "        self.weights = nn.Parameter(atom_list)\n",
    "        self.weights_ = self.weights.clone()\n",
    "        atom_num = len(atom_list)\n",
    "\n",
    "        self.ind_inter = torch.combinations(torch.arange(self.weights.size(0)), r=2).to(device)\n",
    "        ind_inter_f = torch.fliplr(self.ind_inter)\n",
    "        ind_all = torch.cat((self.ind_inter, ind_inter_f), dim=0)\n",
    "        ind_all = ind_all[ind_all[:, 0].sort()[1]]\n",
    "        self.ind_block = torch.split(ind_all, atom_num-1)\n",
    "\n",
    "        self.rho_list = torch.zeros(atom_num)\n",
    "        self.range = torch.arange(atom_num)\n",
    "        self.params = param_list\n",
    "\n",
    "    def f_r(self, r, param):\n",
    "        '''\n",
    "        Basis function for f(r), tag 1-2\n",
    "        Param is nD\n",
    "        '''\n",
    "        f_e, beta, r_e, lamda = torch.tensor_split(param, param.size(1), dim=1)\n",
    "        f_e, beta, r_e, lamda = torch.flatten(f_e), torch.flatten(beta), torch.flatten(r_e), torch.flatten(lamda)\n",
    "\n",
    "        nume = f_e*torch.exp(-beta*(r/r_e-1))\n",
    "        deno = 1 + (r/r_e-lamda)**20\n",
    "        return nume/deno \n",
    "\n",
    "    def phi_r(self, r, param):\n",
    "        ''' \n",
    "        Potential for tag 2-1, atomic pair for same species.\n",
    "        Param is nD.\n",
    "        '''\n",
    "        a, b, r_e, alpha, beta, kappa, lamda = torch.tensor_split(param, param.size(1), dim=1)\n",
    "        a, b = torch.flatten(a), torch.flatten(b)\n",
    "        r_e, alpha, beta = torch.flatten(r_e), torch.flatten(alpha), torch.flatten(beta)\n",
    "        kappa, lamda = torch.flatten(kappa), torch.flatten(lamda)\n",
    "\n",
    "        l_nume = a*torch.exp(-alpha*(r/r_e-1))\n",
    "        l_deno = 1 + (r/r_e-kappa)**20\n",
    "        r_nume = b*torch.exp(-beta*(r/r_e-1))\n",
    "        r_deno = 1 + (r/r_e-lamda)**20\n",
    "\n",
    "        return l_nume/l_deno - r_nume/r_deno\n",
    "\n",
    "    def f_rho(self, rho, param):\n",
    "        ''' \n",
    "        Density function for tag 3-2, param is 1D for the centre atom\n",
    "        '''\n",
    "        f_n0, f_n1, f_n2, f_n3, f_0, f_1, f_2, f_3, f_e, rho_n, rho_e, rho_0, rho_s, eta = param\n",
    "        if rho < rho_n:\n",
    "            return (f_n0 + f_n1*(rho/rho_n-1)\n",
    "                + f_n2*(rho/rho_n-1)**2 + f_n3*(rho/rho_n-1)**3)\n",
    "        elif rho_n <= rho < rho_0:\n",
    "            return (f_0 + f_1*(rho/rho_e-1)\n",
    "                + f_2*(rho/rho_e-1)**2 + f_3*(rho/rho_e-1)**3)\n",
    "        else:\n",
    "            return f_e*(1-torch.log((rho/rho_s)**eta))*(rho/rho_s)**eta\n",
    "\n",
    "    def forward(self,):\n",
    "        ''' \n",
    "        Calculate the whole energy with keeping gradient\n",
    "        '''\n",
    "        coord_inter = self.weights[self.ind_inter]\n",
    "        param_inter = self.params[self.ind_inter]\n",
    "        r_res = torch.norm(coord_inter[:,1]-coord_inter[:,0], dim=1)\n",
    "        #* So this will be the cutoff ?\n",
    "        effe_r_ind = torch.nonzero(r_res <= 16)\n",
    "        r_res = r_res[torch.flatten(effe_r_ind)]\n",
    "        param_inter = param_inter[torch.flatten(effe_r_ind)]\n",
    "\n",
    "        fr_0 = self.f_r(r_res, param_inter[:, 0][:, [1, 5, 0, 9]]) #* For f^0(r)\n",
    "        fr_1 = self.f_r(r_res, param_inter[:, 1][:, [1, 5, 0, 9]]) #* For f^1(r)\n",
    "        phir_0 = self.phi_r(r_res, param_inter[:, 0][:, [6,7,0,4,5,8,9]]) #* For phi^0(r)\n",
    "        phir_1 = self.phi_r(r_res, param_inter[:, 1][:, [6,7,0,4,5,8,9]]) #* For phi^1(r)\n",
    "        phi_01 = fr_1/fr_0*phir_0 + fr_0/fr_1*phir_1 #* For phi^01\n",
    "        p_e = 1/2*torch.sum(phi_01) #* Potential energy term\n",
    "\n",
    "        for r_ind in self.range:\n",
    "            '''\n",
    "            Extract each atom block containing the centre i and surronding j\n",
    "            '''\n",
    "            block = self.ind_block[r_ind]\n",
    "            coord_block = self.weights[block]\n",
    "            param_block = self.params[block]\n",
    "            r_blo = torch.norm(coord_block[:,1]-coord_block[:,0], dim=1)\n",
    "            #* So this will be the cutoff ~5 NN?\n",
    "            effe_r_ind = torch.nonzero(r_blo <= 16)\n",
    "            r_blo = r_blo[torch.flatten(effe_r_ind)]\n",
    "            param_block = param_block[torch.flatten(effe_r_ind)]\n",
    "\n",
    "            rho_i = torch.sum(self.f_r(r_blo, param_block[:, 1][:, [1, 5, 0, 9]])) #* For f^1(r)\n",
    "            f_rho_ = self.f_rho(rho_i, param_block[:, 0][:, [10,11,12,13,14,15,16,17,19,20,2,21,3,18]][0]) #* For F(rho)\n",
    "\n",
    "            self.rho_list[r_ind] = f_rho_\n",
    "\n",
    "        # print(p_e, self.rho_list)\n",
    "        e_all = p_e + torch.sum(self.rho_list)\n",
    "        return e_all\n",
    "\n",
    "def train(model, optimizer, scheduler, path_save, device=None, n = 1000):\n",
    "    # if device is not None:\n",
    "    #     iteration = torch.arange(n).to(device)\n",
    "    # else:\n",
    "    #     iteration = torch.arange(n)\n",
    "    writer = SummaryWriter(log_dir = path_save)\n",
    "    for i in range(n):\n",
    "        loss = model.forward()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # if i % 100 == 0:\n",
    "        #     print(i)\n",
    "        writer.add_scalar(\"Training Loss\", loss, i)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2550214/109256385.py:16: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  self.ind_inter = torch.combinations(torch.arange(self.weights.size(0)), r=2).to(device)\n",
      "2022-10-26 16:50:55.592809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 16:50:55.712507: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-26 16:50:55.731471: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-26 16:50:56.152325: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 16:50:56.152362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 16:50:56.152365: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f74bd79b880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' \n",
    "Generate the primary CoNi cell in planar FCC lattice\n",
    "'''\n",
    "x_extend, y_extend = 5, 5\n",
    "r_equ = 2.49255140368258\n",
    "cell = supercell_gen(x_extend, y_extend)\n",
    "cell_t = np.array(cell, dtype=bool)\n",
    "init_weight = np.array([math.sqrt(3)/2*r_equ, 1/2*r_equ])\n",
    "coord = np.concatenate([np.where(cell_t)[0].reshape(-1,1),\n",
    "                        np.where(cell_t)[1].reshape(-1,1)], 1)*init_weight\n",
    "\n",
    "coord = torch.from_numpy(coord.astype(np.float32)).clone().requires_grad_()\n",
    "atom_num = len(coord)\n",
    "# coord = torch.rand(atom_num, 2)*torch.sqrt(torch.tensor(atom_num)).requires_grad_()\n",
    "\n",
    "n_co = atom_num//2\n",
    "n_ni = atom_num - n_co\n",
    "\n",
    "''' \n",
    "Embed the corresponding params, also determines the atom specie\n",
    "'''\n",
    "p_nico = torch.tensor([\n",
    "    [2.488746, 2.007018, 27.562015, 27.930410, 8.383453, 4.471175,\n",
    "    0.429046, 0.633531, 0.443599, 0.820658, -2.693513, -0.076445, 0.241442,\n",
    "    -2.375626, -2.7, 0, 0.265390, -0.152856, 0.469, -2.699486, \n",
    "    27.562015*0.85, 27.562015*1.15],\n",
    "    [2.505979, 1.975299, 27.206789, 27.206789, 8.679625, 4.629134,\n",
    "    0.421378, 0.640107, 0.5, 1, -2.541799, -0.219415, 0.733381, -1.589003,\n",
    "    -2.56, 0, 0.705845, -0.687140, 0.694608, -2.559307,\n",
    "    27.206789*0.85, 27.206789*1.15]\n",
    "])\n",
    "ele_co = torch.cat((torch.zeros((n_co, 1)), torch.ones((n_co, 1))), dim=1)\n",
    "ele_ni = torch.cat((torch.ones((n_ni, 1)), torch.zeros((n_ni, 1))), dim=1)\n",
    "ele_list_relax = torch.cat((ele_co, ele_ni), dim=0)\n",
    "shuffle_i = torch.randperm(ele_list_relax.size(0))\n",
    "ele_list = ele_list_relax[shuffle_i]\n",
    "\n",
    "#* Execution\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "param_ = torch.matmul(ele_list, p_nico).to(device)\n",
    "coord.to(device)\n",
    "localtime = time.localtime(time.time())\n",
    "yr_, m_, d_ = localtime[:3]\n",
    "date = f'{yr_}{m_}{d_}_relax'\n",
    "pth = f'/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/runs/{date}'\n",
    "\n",
    "m_relax = model(coord, param_).to(device)\n",
    "# Instantiate optimizer\n",
    "opt = torch.optim.Adam(m_relax.parameters(), lr=1e-2)\n",
    "sch = torch.optim.lr_scheduler.StepLR(opt, step_size=1000, gamma = 0.98)\n",
    "\n",
    "losses = train(m_relax, opt, sch, pth, device, n=400)\n",
    "weight_ = m_relax.weights.detach().cpu().numpy()\n",
    "weight_raw = m_relax.weights_.detach().cpu().numpy()\n",
    "np.save(pth+'weight.npy', weight_)\n",
    "np.save(pth+'ele_list.npy', ele_list)\n",
    "\n",
    "plt.scatter(weight_[:, 0], weight_[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, atom_list, param_list, mass_list, v_list, device):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        atom_list: N*dimension\n",
    "        param_list: N*number of params per each atom\n",
    "        per each row:\n",
    "        r_e, f_e, rho_e, rho_s, alpha, beta, A, B, kappa, lamda,\n",
    "        f_n0, f_n1, f_n2, f_n3, f_0, f_1, f_2, f_3, eta, f_e\n",
    "        '''\n",
    "        #* row1: x-coord, row2: y-coord\n",
    "        # self.weights = nn.Parameter(atom_list)\n",
    "        self.weights = atom_list\n",
    "        self.weights_ = self.weights.clone()\n",
    "        atom_num = len(atom_list)\n",
    "\n",
    "        self.ind_inter = torch.combinations(torch.arange(self.weights.size(0)), r=2).to(device)\n",
    "        ind_inter_f = torch.fliplr(self.ind_inter)\n",
    "        ind_all = torch.cat((self.ind_inter, ind_inter_f), dim=0)\n",
    "        ind_all = ind_all[ind_all[:, 0].sort()[1]]\n",
    "        self.ind_block = torch.split(ind_all, atom_num-1)\n",
    "\n",
    "        self.rho_list = torch.zeros(atom_num).to(device)\n",
    "        self.pe_list = torch.zeros(atom_num).to(device)\n",
    "        self.acc_list = torch.zeros(atom_num, self.weights.size(1)).to(device)\n",
    "        self.v_list = v_list\n",
    "        self.mass = mass_list\n",
    "\n",
    "        self.range = torch.arange(atom_num).to(device)\n",
    "        self.params = param_list\n",
    "        # self.opt = torch.optim.Adam([self.weights])\n",
    "\n",
    "    def f_r(self, r, param):\n",
    "        '''\n",
    "        Basis function for f(r), tag 1-2\n",
    "        Param is nD\n",
    "        '''\n",
    "\n",
    "        f_e, beta, r_e, lamda = torch.tensor_split(param, param.size(1), dim=1)\n",
    "        f_e, beta, r_e, lamda = torch.flatten(f_e), torch.flatten(beta), torch.flatten(r_e), torch.flatten(lamda)\n",
    "        \n",
    "        nume = f_e*torch.exp(-beta*(r/r_e-1))\n",
    "        deno = 1 + (r/r_e-lamda)**20\n",
    "        return nume/deno \n",
    "\n",
    "    def phi_r(self, r, param):\n",
    "        ''' \n",
    "        Potential for tag 2-1, atomic pair for same species.\n",
    "        Param is nD.\n",
    "        '''\n",
    "        a, b, r_e, alpha, beta, kappa, lamda = torch.tensor_split(param, param.size(1), dim=1)\n",
    "        a, b = torch.flatten(a), torch.flatten(b)\n",
    "        r_e, alpha, beta = torch.flatten(r_e), torch.flatten(alpha), torch.flatten(beta)\n",
    "        kappa, lamda = torch.flatten(kappa), torch.flatten(lamda)\n",
    "\n",
    "        l_nume = a*torch.exp(-alpha*(r/r_e-1))\n",
    "        l_deno = 1 + (r/r_e-kappa)**20\n",
    "        r_nume = b*torch.exp(-beta*(r/r_e-1))\n",
    "        r_deno = 1 + (r/r_e-lamda)**20\n",
    "\n",
    "        return l_nume/l_deno - r_nume/r_deno\n",
    "\n",
    "    def f_rho(self, rho, param):\n",
    "        ''' \n",
    "        Density function for tag 3-2, param is 1D for the centre atom\n",
    "        '''\n",
    "        f_n0, f_n1, f_n2, f_n3, f_0, f_1, f_2, f_3, f_e, rho_n, rho_e, rho_0, rho_s, eta = param\n",
    "        if rho < rho_n:\n",
    "            return (f_n0 + f_n1*(rho/rho_n-1)\n",
    "                + f_n2*(rho/rho_n-1)**2 + f_n3*(rho/rho_n-1)**3)\n",
    "        elif rho_n <= rho < rho_0:\n",
    "            return (f_0 + f_1*(rho/rho_e-1)\n",
    "                + f_2*(rho/rho_e-1)**2 + f_3*(rho/rho_e-1)**3)\n",
    "        else:\n",
    "            return f_e*(1-torch.log((rho/rho_s)**eta))*(rho/rho_s)**eta\n",
    "\n",
    "    def grad_calc(self,):\n",
    "        ''' \n",
    "        Calculate the whole energy with keeping gradient\n",
    "        '''\n",
    "\n",
    "        for r_ind in self.range:\n",
    "            '''\n",
    "            Extract each atom block containing the centre i and surronding j.\n",
    "            r_ind corresponds to the index of centre atom.\n",
    "            '''\n",
    "            block = self.ind_block[r_ind]\n",
    "            coord_block = self.weights[block]\n",
    "            param_block = self.params[block]\n",
    "\n",
    "            delta_xy = coord_block[:,1]-coord_block[:,0]\n",
    "            r_blo = torch.norm(delta_xy, dim=1)\n",
    "            #* So this will be the cutoff ~3 NN?\n",
    "            effe_r_ind = torch.nonzero(r_blo <= 6)\n",
    "            r_blo = r_blo[torch.flatten(effe_r_ind)]\n",
    "            # print(r_blo)\n",
    "            r_blo.requires_grad_()\n",
    "            param_block = param_block[torch.flatten(effe_r_ind)]\n",
    "            delta_xy = delta_xy[torch.flatten(effe_r_ind)]\n",
    "\n",
    "            #* Potential energy\n",
    "            \n",
    "            fr_0 = self.f_r(r_blo, param_block[:, 0][:, [1, 5, 0, 9]]) #* For f^0(r)\n",
    "            fr_1 = self.f_r(r_blo, param_block[:, 1][:, [1, 5, 0, 9]]) #* For f^1(r)\n",
    "            phir_0 = self.phi_r(r_blo, param_block[:, 0][:, [6,7,0,4,5,8,9]]) #* For phi^0(r)\n",
    "            phir_1 = self.phi_r(r_blo, param_block[:, 1][:, [6,7,0,4,5,8,9]]) #* For phi^1(r)\n",
    "            phi_01 = 1/2*(fr_1/fr_0*phir_0 + fr_0/fr_1*phir_1) #* For phi^01\n",
    "            p_e_ = torch.sum(phi_01) #* Potential energy term\n",
    "\n",
    "            #* Electronic density\n",
    "            rho_i = torch.sum(self.f_r(r_blo, param_block[:, 1][:, [1, 5, 0, 9]])) #* For f^1(r)\n",
    "            f_rho_ = self.f_rho(rho_i, param_block[:, 0][:, [10,11,12,13,14,15,16,17,19,20,2,21,3,18]][0]) #* For F(rho)\n",
    "\n",
    "            self.rho_list[r_ind] = f_rho_\n",
    "            self.pe_list[r_ind] = p_e_\n",
    "            e_x = f_rho_ + 1/2*p_e_\n",
    "\n",
    "            e_x.backward(retain_graph = True)\n",
    "            acc = torch.sum(r_blo.grad.reshape(-1,1)*delta_xy/r_blo.reshape(-1,1), dim=0)/self.mass[r_ind] #*N*2\n",
    "            self.acc_list[r_ind] = acc.clone()\n",
    "            \n",
    "            r_blo.detach()\n",
    "            del r_blo\n",
    "\n",
    "        # print(p_e, self.rho_list)\n",
    "        self.e_total = (torch.sum(self.rho_list) + 1/2*torch.sum(self.pe_list)).detach()\n",
    "        return \n",
    "\n",
    "\n",
    "def train(model_, path_save, dt, temp_given, alpha, device=None, n = 1000):\n",
    "\n",
    "    writer = SummaryWriter(log_dir = path_save)\n",
    "    length = len(model_.weights)\n",
    "    k_b = constants.k\n",
    "    ev_j = constants.physical_constants['atomic unit of charge'][0]\n",
    "    ''' \n",
    "    v_list: angstrom / s\n",
    "    acc: angstrom / s^2\n",
    "    e_total: eV\n",
    "    kinetic, potential energy in Tensorboard: eV\n",
    "    '''\n",
    "\n",
    "    for i in range(n):\n",
    "        #* Step 1\n",
    "        model_.grad_calc()\n",
    "        model_.acc_list *= (ev_j*1e20) #* eV -> J\n",
    "        with torch.no_grad():\n",
    "            model_.weights += (model_.v_list*dt + 1/2*model_.acc_list*dt**2) #* x-step\n",
    "        model_.v_list += 1/2*model_.acc_list*dt\n",
    "        model_.v_list -= torch.sum(model_.v_list, 0)/length\n",
    "\n",
    "        #* Step 2\n",
    "        model_.grad_calc()\n",
    "        model_.acc_list *= (ev_j*1e20)\n",
    "        model_.v_list += 1/2*model_.acc_list*dt\n",
    "        model_.v_list -= torch.sum(model_.v_list, 0)/length\n",
    "        k_e_ = 1/2*torch.sum(model_.mass.reshape(-1,1)*(model_.v_list*1e-10)**2)\n",
    "        temp_ = k_e_/(3/2*(length-1))/k_b\n",
    "\n",
    "        writer.add_scalar(\"Potential energy\", model_.e_total, i)\n",
    "        writer.add_scalar(\"Kinetic energy\", k_e_/ev_j, i)\n",
    "        writer.add_scalar(\"Temperature\", temp_, i)\n",
    "\n",
    "        if i%100 == 0:\n",
    "            s_adjust = torch.sqrt((temp_given+(temp_-temp_given)*alpha)/temp_)\n",
    "            model_.v_list *= s_adjust\n",
    "\n",
    "            # clear_output(True)\n",
    "\n",
    "#! Periodic boundary condition\n",
    "#! Check latent bug (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ],\n",
       "       [ 0.        ,  2.4925514 ],\n",
       "       [ 0.        ,  4.98510281],\n",
       "       [ 0.        ,  7.47765421],\n",
       "       [ 0.        ,  9.97020561],\n",
       "       [ 0.        , 12.46275702],\n",
       "       [ 2.15861284,  1.2462757 ],\n",
       "       [ 2.15861284,  3.73882711],\n",
       "       [ 2.15861284,  6.23137851],\n",
       "       [ 2.15861284,  8.72392991],\n",
       "       [ 2.15861284, 11.21648132],\n",
       "       [ 4.31722567,  0.        ],\n",
       "       [ 4.31722567,  2.4925514 ],\n",
       "       [ 4.31722567,  4.98510281],\n",
       "       [ 4.31722567,  7.47765421],\n",
       "       [ 4.31722567,  9.97020561],\n",
       "       [ 4.31722567, 12.46275702],\n",
       "       [ 6.47583851,  1.2462757 ],\n",
       "       [ 6.47583851,  3.73882711],\n",
       "       [ 6.47583851,  6.23137851],\n",
       "       [ 6.47583851,  8.72392991],\n",
       "       [ 6.47583851, 11.21648132],\n",
       "       [ 8.63445134,  0.        ],\n",
       "       [ 8.63445134,  2.4925514 ],\n",
       "       [ 8.63445134,  4.98510281],\n",
       "       [ 8.63445134,  7.47765421],\n",
       "       [ 8.63445134,  9.97020561],\n",
       "       [ 8.63445134, 12.46275702],\n",
       "       [10.79306418,  1.2462757 ],\n",
       "       [10.79306418,  3.73882711],\n",
       "       [10.79306418,  6.23137851],\n",
       "       [10.79306418,  8.72392991],\n",
       "       [10.79306418, 11.21648132],\n",
       "       [12.95167701,  0.        ],\n",
       "       [12.95167701,  2.4925514 ],\n",
       "       [12.95167701,  4.98510281],\n",
       "       [12.95167701,  7.47765421],\n",
       "       [12.95167701,  9.97020561],\n",
       "       [12.95167701, 12.46275702],\n",
       "       [15.11028985,  1.2462757 ],\n",
       "       [15.11028985,  3.73882711],\n",
       "       [15.11028985,  6.23137851],\n",
       "       [15.11028985,  8.72392991],\n",
       "       [15.11028985, 11.21648132],\n",
       "       [17.26890269,  0.        ],\n",
       "       [17.26890269,  2.4925514 ],\n",
       "       [17.26890269,  4.98510281],\n",
       "       [17.26890269,  7.47765421],\n",
       "       [17.26890269,  9.97020561],\n",
       "       [17.26890269, 12.46275702],\n",
       "       [19.42751552,  1.2462757 ],\n",
       "       [19.42751552,  3.73882711],\n",
       "       [19.42751552,  6.23137851],\n",
       "       [19.42751552,  8.72392991],\n",
       "       [19.42751552, 11.21648132],\n",
       "       [21.58612836,  0.        ],\n",
       "       [21.58612836,  2.4925514 ],\n",
       "       [21.58612836,  4.98510281],\n",
       "       [21.58612836,  7.47765421],\n",
       "       [21.58612836,  9.97020561],\n",
       "       [21.58612836, 12.46275702]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_extend, y_extend = 5, 5\n",
    "r_equ = 2.49255140368258\n",
    "cell = supercell_gen(x_extend, y_extend)\n",
    "cell_t = np.array(cell, dtype=bool)\n",
    "init_weight = np.array([math.sqrt(3)/2*r_equ, 1/2*r_equ])\n",
    "coord = np.concatenate([np.where(cell_t)[0].reshape(-1,1),\n",
    "                        np.where(cell_t)[1].reshape(-1,1)], 1)*init_weight\n",
    "\n",
    "coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2, -1],\n",
      "        [-2, -1],\n",
      "        [-2, -1]]) tensor([[23, 13],\n",
      "        [23, 13],\n",
      "        [23, 13]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2, -1],\n",
       "        [12, 11],\n",
       "        [20,  0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_upper, x_lower = (x_extend+1/2)*r_equ*math.sqrt(3), -(1/2)*r_equ*math.sqrt(3)\n",
    "y_upper, y_lower = (y_extend+1/2)*r_equ, -(1/2)*r_equ\n",
    "atom_num = 3\n",
    "\n",
    "x_u = torch.ones(atom_num)*x_upper\n",
    "x_l = torch.ones(atom_num)*x_lower\n",
    "\n",
    "y_u = torch.ones(atom_num)*y_upper\n",
    "y_l = torch.ones(atom_num)*y_lower\n",
    "\n",
    "xy_l = torch.cat((x_l.reshape(-1,1), y_l.reshape(-1,1)), dim=1).long()\n",
    "xy_u = torch.cat((x_u.reshape(-1,1), y_u.reshape(-1,1)), dim=1).long()\n",
    "print(xy_l, xy_u)\n",
    "\n",
    "a = torch.tensor([ \n",
    "    [23, -1],\n",
    "    [12, 11],\n",
    "    [-5, 14]\n",
    "])\n",
    "\n",
    "a = torch.where(a > xy_l, a, a+xy_u-xy_l)\n",
    "a = torch.where(a < xy_u, a, a-xy_u+xy_l)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.363925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_list = []\n",
    "coord_ = np.load('/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/runs/20221026_relaxweight.npy')\n",
    "for i in ind_1nn:\n",
    "    a1, a2 = coord_[i[0]], coord_[i[1]]\n",
    "    dis_list.append(np.linalg.norm(a1-a2))\n",
    "np.mean(dis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    use_relax = True\n",
    "    ''' \n",
    "    Generate the primary CoNi cell in planar FCC lattice\n",
    "    '''\n",
    "    x_extend, y_extend = 3, 3\n",
    "    r_equ = 2.49255140368258\n",
    "    cell = supercell_gen(x_extend, y_extend)\n",
    "    cell_t = np.array(cell, dtype=bool)\n",
    "    init_weight = np.array([math.sqrt(3)/2*r_equ, 1/2*r_equ])\n",
    "    coord = np.concatenate([np.where(cell_t)[0].reshape(-1,1),\n",
    "                            np.where(cell_t)[1].reshape(-1,1)], 1)*init_weight\n",
    "\n",
    "    if use_relax:\n",
    "        coord = np.load('/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/runs/20221026_relaxweight.npy')\n",
    "\n",
    "    coord = torch.from_numpy(coord.astype(np.float32)).clone()\n",
    "    atom_num = len(coord)\n",
    "    atom_dim = coord.size(1)\n",
    "\n",
    "    n_co = atom_num//2\n",
    "    n_ni = atom_num - n_co\n",
    "\n",
    "    ''' \n",
    "    Embed the corresponding params, also determines the atom specie\n",
    "    '''\n",
    "    p_nico = torch.tensor([\n",
    "        [2.488746, 2.007018, 27.562015, 27.930410, 8.383453, 4.471175,\n",
    "        0.429046, 0.633531, 0.443599, 0.820658, -2.693513, -0.076445, 0.241442,\n",
    "        -2.375626, -2.7, 0, 0.265390, -0.152856, 0.469, -2.699486, \n",
    "        27.562015*0.85, 27.562015*1.15], #* Ni\n",
    "        [2.505979, 1.975299, 27.206789, 27.206789, 8.679625, 4.629134,\n",
    "        0.421378, 0.640107, 0.5, 1, -2.541799, -0.219415, 0.733381, -1.589003,\n",
    "        -2.56, 0, 0.705845, -0.687140, 0.694608, -2.559307,\n",
    "        27.206789*0.85, 27.206789*1.15] #* Co\n",
    "    ])\n",
    "    m_nico = torch.tensor([ \n",
    "        [58.6934],\n",
    "        [58.9332]\n",
    "    ])*constants.u\n",
    "\n",
    "    ele_co = torch.cat((torch.zeros((n_co, 1)), torch.ones((n_co, 1))), dim=1)\n",
    "    ele_ni = torch.cat((torch.ones((n_ni, 1)), torch.zeros((n_ni, 1))), dim=1)\n",
    "    ele_list = torch.cat((ele_co, ele_ni), dim=0)\n",
    "    shuffle_i = torch.randperm(ele_list.size(0))\n",
    "    ele_list = ele_list[shuffle_i]\n",
    "    if use_relax:\n",
    "        ele_list = np.load('/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/runs/20221026_relaxele_list.npy')\n",
    "        ele_list = torch.from_numpy(ele_list.astype(np.float32))\n",
    "\n",
    "    #* Execution\n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    param_ = torch.matmul(ele_list, p_nico)\n",
    "    mass_ = torch.flatten(torch.matmul(ele_list, m_nico))\n",
    "\n",
    "\n",
    "    #* Velocity\n",
    "    temp = 200\n",
    "    k_b = constants.k\n",
    "    v_list = torch.rand(atom_num, atom_dim)*torch.sqrt(3*(1-1/atom_dim)*k_b*temp/mass_.reshape(-1,1))*1e10\n",
    "    v_list -= torch.sum(v_list, 0)/atom_num\n",
    "\n",
    "    #* To device\n",
    "    v_list = v_list.to(device)\n",
    "    mass_ = mass_.to(device)\n",
    "    param_ = param_.to(device)\n",
    "    coord = coord.to(device)\n",
    "\n",
    "\n",
    "    localtime = time.localtime(time.time())\n",
    "    yr_, m_, d_ = localtime[:3]\n",
    "    date = f'{yr_}{m_}{d_}'\n",
    "    pth = f'/media/wz/a7ee6d50-691d-431a-8efb-b93adc04896d/Github/pyMD/2D_try/EAM/runs/{date}'\n",
    "\n",
    "    m = model(coord, param_, mass_, v_list, device).to(device)\n",
    "\n",
    "    dt = torch.tensor(1e-15).to(device) #* Time step, 1 fs = 1e-15 s\n",
    "    alpha = 0.75 #* For temperature adjusting\n",
    "    train(m, pth, dt, temp, alpha, device, n=1000)\n",
    "    weight_ = m.weights.detach().cpu().numpy()\n",
    "    weight_raw = m.weights_.detach().cpu().numpy()\n",
    "    plt.scatter(weight_[:, 0], weight_[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68475d8e8ba7c27bff5b0c1dcce162ecdafd8f583568d2d03f898fe272d0ccc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
